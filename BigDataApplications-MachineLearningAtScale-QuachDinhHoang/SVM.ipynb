{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Hướng dẫn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi tạo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count,lit\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Support Vector Machine (SVM)\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc và load tập dữ liệu Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2|Iris-setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1|Iris-setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1|Iris-setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisDF = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .csv(\"./iris.csv\")\n",
    "         )\n",
    "\n",
    "irisDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển cột `class` (kiểu string) thành `label` (kiểu double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|label|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|  0.0|\n",
      "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|  0.0|\n",
      "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|  0.0|\n",
      "|         5.4|        3.7|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         4.8|        3.4|         1.6|        0.2|Iris-setosa|  0.0|\n",
      "|         4.8|        3.0|         1.4|        0.1|Iris-setosa|  0.0|\n",
      "|         4.3|        3.0|         1.1|        0.1|Iris-setosa|  0.0|\n",
      "|         5.8|        4.0|         1.2|        0.2|Iris-setosa|  0.0|\n",
      "|         5.7|        4.4|         1.5|        0.4|Iris-setosa|  0.0|\n",
      "|         5.4|        3.9|         1.3|        0.4|Iris-setosa|  0.0|\n",
      "|         5.1|        3.5|         1.4|        0.3|Iris-setosa|  0.0|\n",
      "|         5.7|        3.8|         1.7|        0.3|Iris-setosa|  0.0|\n",
      "|         5.1|        3.8|         1.5|        0.3|Iris-setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "class_indexer = StringIndexer(inputCol='class',outputCol='label')\n",
    "\n",
    "irisDFindexed = class_indexer.fit(irisDF).transform(irisDF)\n",
    "\n",
    "irisDFindexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tập dữ liệu Iris\n",
    "\n",
    "`sepal_length`: chiều dài đài hoa (cm)\n",
    "\n",
    "`sepal_width`: chiều rộng đài hoa (cm)\n",
    "\n",
    "`petal_length`: chiều dài cánh hoa (cm)\n",
    "\n",
    "`petal_width`: chiều rộng cánh hoa (cm)\n",
    "\n",
    "`class/label`: loại hoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chia dữ liệu thành train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainDF, testDF) = irisDFindexed.randomSplit([.8, .2], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xem các loại biến trong tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal_length', 'double'),\n",
       " ('sepal_width', 'double'),\n",
       " ('petal_length', 'double'),\n",
       " ('petal_width', 'double'),\n",
       " ('class', 'string'),\n",
       " ('label', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDFindexed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biến đổi train data và test data theo định dạng của Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[4.3,3.0,1.1,0.1]|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|[4.4,3.0,1.3,0.2]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['sepal_length','sepal_width','petal_length','petal_width'],\n",
    "                            outputCol='features')\n",
    "assembler_train = assembler.transform(trainDF)\n",
    "\n",
    "final_train = assembler_train.select('features','label')\n",
    "final_train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng Linear Support Vector Classifier với One Vs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Huấn luyện mô hình trên `final_train` với `LinearSVC` theo cách tiếp cận `OneVsRest` với `labelCol` là `'lable'` và `featuresCol` là `'features'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "lsvc = LinearSVC(featuresCol='features', labelCol='label', maxIter=10, regParam=0.1)\n",
    "ovr = OneVsRest(classifier=lsvc)\n",
    "ovrModel = ovr.fit(final_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.** Áp dụng mô hình trên test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng biến đổi cho tập test tương tự như trên tập train. In ra vài dòng sau khi biến đổi để xem kết quả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[4.5,2.3,1.3,0.3]|  0.0|\n",
      "|[4.8,3.1,1.6,0.2]|  0.0|\n",
      "|[4.8,3.4,1.6,0.2]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler_test = assembler.transform(testDF)\n",
    "final_test = assembler_test.select('features','label')\n",
    "final_test.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dự đoán trên test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       2.0|  2.0|\n",
      "|       0.0|  0.0|\n",
      "|       2.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       2.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "|       2.0|  2.0|\n",
      "|       2.0|  1.0|\n",
      "|       2.0|  1.0|\n",
      "|       2.0|  1.0|\n",
      "|       2.0|  2.0|\n",
      "|       2.0|  1.0|\n",
      "|       2.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ovrModel.transform(final_test)\n",
    "predictions.select(\"prediction\", \"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3.** Tính giá trị `Accuracy` của mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.730769\n",
      "Test Error = 0.269231\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Áp dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1 - Áp dụng `LinearSVC` với tập dữ liệu `Auto`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu hỏi này sử dụng SVM trên tập dữ liệu `Auto` để dự đoán một xe cho trước có `mpg` là `high` hay `low`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.** Tạo một binary variable nhận giá trị 1 (`high`) với các xe có `mpg` lớn hơn median mpg, và nhận giá trị 0 (`low`) cho các xe còn lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: integer (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- horsepower: string (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- origin: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Viết code của bạn ở đây\n",
    "autoDF = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .csv(\"./Auto.csv\")\n",
    "         )\n",
    "\n",
    "autoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql import functions \n",
    "import numpy as np\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "### https://stackoverflow.com/questions/42826502/pyspark-dataframe-group-by-filtering\n",
    "\n",
    "def median(values):\n",
    "    try:\n",
    "        median = np.median(values)\n",
    "        return round(float(median),2)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "median = functions.udf(median,FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|temp|                 mpg|\n",
      "+----+--------------------+\n",
      "|   1|[18.0, 15.0, 18.0...|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoDF2 = (autoDF.withColumn(\"temp\",functions.lit(1)) \n",
    "            .groupBy(\"temp\")\n",
    "            .agg(functions.collect_list(\"mpg\").alias(\"mpg\"))\n",
    "          )\n",
    "\n",
    "autoDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = autoDF2.withColumn(\"median\", median(\"mpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianOfMPG = temp.collect()[0][\"median\"]\n",
    "\n",
    "# Giá trị median cần tìm\n",
    "medianOfMPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|mpgClassifier|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+\n",
      "|18.0|        8|       307.0|       130|  3504|        12.0|  70|     1|chevrolet chevell...|            0|\n",
      "|15.0|        8|       350.0|       165|  3693|        11.5|  70|     1|   buick skylark 320|            0|\n",
      "|18.0|        8|       318.0|       150|  3436|        11.0|  70|     1|  plymouth satellite|            0|\n",
      "|16.0|        8|       304.0|       150|  3433|        12.0|  70|     1|       amc rebel sst|            0|\n",
      "|17.0|        8|       302.0|       140|  3449|        10.5|  70|     1|         ford torino|            0|\n",
      "|15.0|        8|       429.0|       198|  4341|        10.0|  70|     1|    ford galaxie 500|            0|\n",
      "|14.0|        8|       454.0|       220|  4354|         9.0|  70|     1|    chevrolet impala|            0|\n",
      "|14.0|        8|       440.0|       215|  4312|         8.5|  70|     1|   plymouth fury iii|            0|\n",
      "|14.0|        8|       455.0|       225|  4425|        10.0|  70|     1|    pontiac catalina|            0|\n",
      "|15.0|        8|       390.0|       190|  3850|         8.5|  70|     1|  amc ambassador dpl|            0|\n",
      "|15.0|        8|       383.0|       170|  3563|        10.0|  70|     1| dodge challenger se|            0|\n",
      "|14.0|        8|       340.0|       160|  3609|         8.0|  70|     1|  plymouth 'cuda 340|            0|\n",
      "|15.0|        8|       400.0|       150|  3761|         9.5|  70|     1|chevrolet monte c...|            0|\n",
      "|14.0|        8|       455.0|       225|  3086|        10.0|  70|     1|buick estate wago...|            0|\n",
      "|24.0|        4|       113.0|        95|  2372|        15.0|  70|     3|toyota corona mar...|            1|\n",
      "|22.0|        6|       198.0|        95|  2833|        15.5|  70|     1|     plymouth duster|            0|\n",
      "|18.0|        6|       199.0|        97|  2774|        15.5|  70|     1|          amc hornet|            0|\n",
      "|21.0|        6|       200.0|        85|  2587|        16.0|  70|     1|       ford maverick|            0|\n",
      "|27.0|        4|        97.0|        88|  2130|        14.5|  70|     3|        datsun pl510|            1|\n",
      "|26.0|        4|        97.0|        46|  1835|        20.5|  70|     2|volkswagen 1131 d...|            1|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoDF = autoDF.withColumn(\"mpgClassifier\", functions.when(functions.col(\"mpg\") >= medianOfMPG, 1).otherwise(0))\n",
    "\n",
    "autoDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.** Áp dụng linear support vector classiﬁer cho tập dữ liệu với các giá trị siêu tham số `regParam` khác nhau để dự đoán `mpg`. Cho biết cross-validation error ứng với các giá trị khác nhau của siêu tham số này. Nhận xét kết quả thu được. Tham khảo document về linear support vector classiﬁer của Spark ở [LinearSVC](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LinearSVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+-----+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|mpgClassifier|label|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+-----+\n",
      "|18.0|        8|       307.0|       130|  3504|        12.0|  70|     1|chevrolet chevell...|            0|  1.0|\n",
      "|15.0|        8|       350.0|       165|  3693|        11.5|  70|     1|   buick skylark 320|            0|  1.0|\n",
      "|18.0|        8|       318.0|       150|  3436|        11.0|  70|     1|  plymouth satellite|            0|  1.0|\n",
      "|16.0|        8|       304.0|       150|  3433|        12.0|  70|     1|       amc rebel sst|            0|  1.0|\n",
      "|17.0|        8|       302.0|       140|  3449|        10.5|  70|     1|         ford torino|            0|  1.0|\n",
      "|15.0|        8|       429.0|       198|  4341|        10.0|  70|     1|    ford galaxie 500|            0|  1.0|\n",
      "|14.0|        8|       454.0|       220|  4354|         9.0|  70|     1|    chevrolet impala|            0|  1.0|\n",
      "|14.0|        8|       440.0|       215|  4312|         8.5|  70|     1|   plymouth fury iii|            0|  1.0|\n",
      "|14.0|        8|       455.0|       225|  4425|        10.0|  70|     1|    pontiac catalina|            0|  1.0|\n",
      "|15.0|        8|       390.0|       190|  3850|         8.5|  70|     1|  amc ambassador dpl|            0|  1.0|\n",
      "|15.0|        8|       383.0|       170|  3563|        10.0|  70|     1| dodge challenger se|            0|  1.0|\n",
      "|14.0|        8|       340.0|       160|  3609|         8.0|  70|     1|  plymouth 'cuda 340|            0|  1.0|\n",
      "|15.0|        8|       400.0|       150|  3761|         9.5|  70|     1|chevrolet monte c...|            0|  1.0|\n",
      "|14.0|        8|       455.0|       225|  3086|        10.0|  70|     1|buick estate wago...|            0|  1.0|\n",
      "|24.0|        4|       113.0|        95|  2372|        15.0|  70|     3|toyota corona mar...|            1|  0.0|\n",
      "|22.0|        6|       198.0|        95|  2833|        15.5|  70|     1|     plymouth duster|            0|  1.0|\n",
      "|18.0|        6|       199.0|        97|  2774|        15.5|  70|     1|          amc hornet|            0|  1.0|\n",
      "|21.0|        6|       200.0|        85|  2587|        16.0|  70|     1|       ford maverick|            0|  1.0|\n",
      "|27.0|        4|        97.0|        88|  2130|        14.5|  70|     3|        datsun pl510|            1|  0.0|\n",
      "|26.0|        4|        97.0|        46|  1835|        20.5|  70|     2|volkswagen 1131 d...|            1|  0.0|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Viết code của bạn ở đây\n",
    "\n",
    "#chuyển cột binary value mpgClassifier vừa làm được thành label kiểu double\n",
    "mpg_indexer = StringIndexer(inputCol='mpgClassifier',outputCol='label')\n",
    "autoDFindexed = mpg_indexer.fit(autoDF).transform(autoDF)\n",
    "autoDFindexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "#Chia dữ liệu thành trainset, \n",
    "(trainDF, testDF) = autoDFindexed.randomSplit([.8, .2], seed=1)\n",
    "\n",
    "print( trainDF.count())\n",
    "print( testDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mpg', 'double'),\n",
       " ('cylinders', 'int'),\n",
       " ('displacement', 'double'),\n",
       " ('horsepower', 'string'),\n",
       " ('weight', 'int'),\n",
       " ('acceleration', 'double'),\n",
       " ('year', 'int'),\n",
       " ('origin', 'int'),\n",
       " ('name', 'string'),\n",
       " ('mpgClassifier', 'int'),\n",
       " ('label', 'double')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Xem các loại biến trong tập dữ liệu\n",
    "autoDFindexed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[8.0,304.0,4732.0...|  1.0|\n",
      "|[8.0,307.0,4376.0...|  1.0|\n",
      "|[8.0,360.0,4615.0...|  1.0|\n",
      "|[8.0,318.0,4382.0...|  1.0|\n",
      "|[8.0,400.0,4997.0...|  1.0|\n",
      "|[8.0,429.0,4633.0...|  1.0|\n",
      "|[8.0,350.0,4456.0...|  1.0|\n",
      "|[8.0,350.0,4499.0...|  1.0|\n",
      "|[8.0,383.0,4955.0...|  1.0|\n",
      "|[8.0,400.0,4906.0...|  1.0|\n",
      "|[8.0,429.0,4952.0...|  1.0|\n",
      "|[8.0,455.0,4951.0...|  1.0|\n",
      "|[8.0,307.0,4098.0...|  1.0|\n",
      "|[8.0,318.0,3940.0...|  1.0|\n",
      "|[8.0,350.0,3988.0...|  1.0|\n",
      "|[8.0,350.0,4055.0...|  1.0|\n",
      "|[8.0,350.0,4699.0...|  1.0|\n",
      "|[8.0,350.0,4502.0...|  1.0|\n",
      "|[8.0,350.0,4274.0...|  1.0|\n",
      "|[8.0,350.0,4100.0...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Biến đổi train data và test data theo định dạng của Spark\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['cylinders','displacement','weight','acceleration','year','origin'],\n",
    "                            outputCol='features')\n",
    "assembler_train = assembler.transform(trainDF)\n",
    "\n",
    "final_train = assembler_train.select('features','label')\n",
    "final_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sử dụng Linear Support Vector Classifier với One Vs Rest\n",
    "### 1.1 Huấn luyện mô hình trên final_train với LinearSVC theo cách tiếp cận OneVsRest với labelCol là 'lable' và featuresCol là 'features'\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "lsvc = LinearSVC(featuresCol='features', labelCol='label', maxIter=10, regParam=0.1)\n",
    "ovr = OneVsRest(classifier=lsvc)\n",
    "ovrModel = ovr.fit(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.2. Áp dụng mô hình trên test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[8.0,350.0,3664.0...|  1.0|\n",
      "|[8.0,302.0,3169.0...|  1.0|\n",
      "|[8.0,302.0,3870.0...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler_test = assembler.transform(testDF)\n",
    "final_test = assembler_test.select('features','label')\n",
    "final_test.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dự đoán trên test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ovrModel.transform(final_test)\n",
    "predictions.select(\"prediction\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       0.0|  1.0|\n",
      "|       1.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\").filter(col(\"prediction\") != col(\"label\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.3. Tính giá trị Accuracy của mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.881579\n",
      "Test Error = 0.118421\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 2 - So sánh các mô hình phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện việc train tất cả các mô hình `LogisticRegression`, `DecisionTreeClassifier` và `RandomForestClassifier`, `GBTClassifier`, `MultilayerPerceptronClassifier`, `LinearSVC`, `NaiveBayes` trên tập một tập dữ liệu cho bài toán phân loại (có từ 10-100 thuộc tính và 100-1000 đối tượng) mà bạn quan tâm ở [UCI Classification Dataset](https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=10to100&numIns=100to1000&type=&sort=nameUp&view=table). Điều chỉnh các siêu tham số của các mô hình để chọn mô hình tốt nhất dùng cross validation. Tham khảo  notebook \"10-7 Hyperparameter Tuning\" ở sách Learning Spark. So sánh và nhận xét về kết quả của các mô hình. Để tránh lặp lại các bước xử lý giống nhau nhiều lần như ở trên bạn nên tạo pipeline các bước xử lý. Tham khảo cách tạo pipeline cho mô hình ở [đây](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier). Tham khảo document về các classifier của Spark ở [classification module](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 3 - So sánh các mô hình hồi quy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện việc train tất cả các mô hình `LinearRegression`, `DecisionTreeRegression` và `RandomForestRegression`, `GBTRegression` trên tập một tập dữ liệu cho bài toán hồi quy (có từ 10-100 thuộc tính và 100-1000 đối tượng) mà bạn quan tâm ở [UCI Regression Dataset](https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=10to100&numIns=100to1000&type=&sort=nameUp&view=table). Điều chỉnh các siêu tham số của các mô hình để chọn mô hình tốt nhất dùng cross validation. Tham khảo  notebook \"10-7 Hyperparameter Tuning\" ở sách Learning Spark. So sánh và nhận xét về kết quả của các mô hình. Để tránh lặp lại các bước xử lý giống nhau nhiều lần như ở trên bạn nên tạo pipeline các bước xử lý. Tham khảo cách tạo pipeline cho mô hình ở [đây](https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier). Tham khảo document về các classifier của Spark ở [regression module](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#module-pyspark.ml.regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
